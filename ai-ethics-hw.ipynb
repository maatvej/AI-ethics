{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43218aea",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643c8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get the same results each time\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load the training data\n",
    "data = pd.read_csv(\"content/data.csv\")\n",
    "comments = data[\"comment_text\"]\n",
    "target = (data[\"target\"] > 0.7).astype(int)\n",
    "\n",
    "# Разделение данных на train и test\n",
    "X_train, X_test, y_train, y_test = train_test_split(comments, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532658a",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1346a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Преобразование текста в числовые данные\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff76ee8",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951f3567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9277254226100986\n"
     ]
    }
   ],
   "source": [
    "# Инициализация логистической регрессии\n",
    "classifier = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# Обучение модели\n",
    "classifier.fit(X_train_counts, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = classifier.predict(X_test_counts)\n",
    "\n",
    "# Расчет accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f81c18d",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d78815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_toxicity(comment):\n",
    "    # Преобразование комментария в числовое представление\n",
    "    comment_counts = vectorizer.transform([comment])\n",
    "    # Предсказание вероятности\n",
    "    probability = classifier.predict_proba(comment_counts)[:, 1]\n",
    "    return probability[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5844ff5e",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b7649f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9991454496873886\n",
      "0.05885369712646557\n"
     ]
    }
   ],
   "source": [
    "# Примеры предсказаний\n",
    "print(predict_toxicity(\"Apples are stupid\"))  # Ожидаем значение близкое к 1\n",
    "print(predict_toxicity(\"I love apples\"))      # Ожидаем значение близкое к 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcaa59f",
   "metadata": {},
   "source": [
    "## Задание 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9044d243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: stupid, Coefficient: 9.248914153050393\n",
      "Word: idiot, Coefficient: 8.713474437073495\n",
      "Word: idiots, Coefficient: 8.440952076056677\n",
      "Word: stupidity, Coefficient: 7.532447834250859\n",
      "Word: idiotic, Coefficient: 6.828585093096055\n",
      "Word: crap, Coefficient: 6.56792271566527\n",
      "Word: dumb, Coefficient: 6.450247704002257\n",
      "Word: pathetic, Coefficient: 6.410854251847928\n",
      "Word: hypocrite, Coefficient: 6.38542948060996\n",
      "Word: moron, Coefficient: 6.351060787642749\n"
     ]
    }
   ],
   "source": [
    "# Получаем список слов и их коэффициентов\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "coefs = classifier.coef_[0]\n",
    "\n",
    "# Индексы самых больших коэффициентов\n",
    "top_indices = coefs.argsort()[-10:][::-1]\n",
    "\n",
    "# Самые токсичные слова и их коэффициенты\n",
    "toxic_words = feature_names[top_indices]\n",
    "toxic_coefs = coefs[top_indices]\n",
    "\n",
    "for word, coef in zip(toxic_words, toxic_coefs):\n",
    "    print(f\"Word: {word}, Coefficient: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242e956",
   "metadata": {},
   "source": [
    "## Задание 7\n",
    "\n",
    "Удивительные слова: нет\n",
    "Слова, которые, возможно, не должны быть в списке: \"pathetic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662a63f",
   "metadata": {},
   "source": [
    "## Задание 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a819f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18760590388569065\n",
      "0.5108092195475886\n",
      "0.40150015555040297\n",
      "0.5887745076141645\n"
     ]
    }
   ],
   "source": [
    "# Примеры предсказаний\n",
    "print(predict_toxicity(\"I have a christian friend\"))\n",
    "print(predict_toxicity(\"I have a muslim friend\"))\n",
    "print(predict_toxicity(\"I have a white friend\"))\n",
    "print(predict_toxicity(\"I have a black friend\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59964adc",
   "metadata": {},
   "source": [
    "### Анализ результатов:\n",
    "\n",
    "1. **\"I have a christian friend\"**:\n",
    "   - Токсичность: **0.187**\n",
    "   - Комментарий кажется нейтральным и не содержит явных оскорблений или дискриминации. Модель правильно классифицирует его как относительно безопасный.\n",
    "\n",
    "2. **\"I have a muslim friend\"**:\n",
    "   - Токсичность: **0.511**\n",
    "   - Этот комментарий также нейтрален, но модель выдает более высокую вероятность токсичности. Это может указывать на потенциальную предвзятость модели в отношении религии, особенно мусульманства.\n",
    "\n",
    "3. **\"I have a white friend\"**:\n",
    "   - Токсичность: **0.402**\n",
    "   - Комментарий нейтрален, но модель снова выдает среднюю вероятность токсичности. Это может быть связано с тем, что упоминание расы само по себе воспринимается моделью как потенциально проблематичное.\n",
    "\n",
    "4. **\"I have a black friend\"**:\n",
    "   - Токсичность: **0.589**\n",
    "   - Здесь модель выдает самую высокую вероятность токсичности среди всех комментариев. Это вызывает серьезные вопросы об этичности модели, так как комментарий остается нейтральным и не содержит явных оскорблений.\n",
    "\n",
    "---\n",
    "\n",
    "### Выводы:\n",
    "\n",
    "1. **Предвзятость (bias)**:\n",
    "   - Модель демонстрирует различную чувствительность к упоминанию различных групп. Особенно примечательно, что комментарии, связанные с мусульманами и чернокожими людьми, получают значительно более высокие значения токсичности, чем комментарии о христианах или белых людях.\n",
    "   - Это может указывать на то, что модель обучена на данных, где такие упоминания часто ассоциировались с токсичными комментариями, что привело к формированию предвзятости.\n",
    "\n",
    "2. **Этика**:\n",
    "   - Высокая токсичность для комментариев, содержащих упоминания определенных религий или рас, является этически проблематичной. Такое поведение модели может способствовать дискриминации и стереотипам, даже если комментарии сами по себе нейтральны.\n",
    "   - Это подчеркивает необходимость дальнейшего анализа и корректировки модели, чтобы избежать дискриминационного воздействия.\n",
    "\n",
    "---\n",
    "\n",
    "### Итоговый ответ:\n",
    "- **Есть ли bias?** Да, модель показывает различную чувствительность к упоминанию религии и расы, что указывает на наличие предвзятости.\n",
    "- **Этичен ли он?** Нет, текущее поведение модели неэтично, так как оно может способствовать дискриминации и стереотипам. Необходимо провести дополнительную работу по устранению этих проблем."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858993ca",
   "metadata": {},
   "source": [
    "## Задание 9\n",
    "\n",
    "Модель демонстрирует предвзятость к комментариям о мусульманах, что может нарушить все четыре критерия этики ИИ:\n",
    "1. **Демографический паритет**: Меньшая доля комментариев о мусульманах будет отмечена как нетоксичные.\n",
    "2. **Равные возможности**: Высокий истинно положительный показатель (TPR) для комментариев о мусульманах.\n",
    "3. **Одинаковая точность**: Разная точность модели для разных групп.\n",
    "4. **Группа по незнанию**: Удаление информации о религии может не полностью избавить модель от предвзятости из-за прокси-переменных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac06150",
   "metadata": {},
   "source": [
    "## Задание 10\n",
    "\n",
    "1. Использование более сложных моделей машинного обучения, таких как случайные леса или нейронные сети.\n",
    "\n",
    "2. Удаление или снижение веса слов, связанных с определенными группами или религиями, чтобы снизить предвзятость модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd5a2a4",
   "metadata": {},
   "source": [
    "## Задание 11\n",
    "\n",
    "1. Использование методов фильтрации для удаления явно токсичных слов или фраз.\n",
    "\n",
    "2. Признаки, учитывающие контекст и эмоциональный оттенок комментариев, а не только наличие определенных слов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
